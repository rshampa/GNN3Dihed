{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ede5a585-8b58-4257-b162-6e36cb73f873",
   "metadata": {},
   "source": [
    "## Know your libraries (KYL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c06257-a4aa-4aa0-a2cc-d61619fb23e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import dataset, molecular_representation, config, utils, model\n",
    "from dataset import QM9Dataset,LogSDataset,LogPDataset,FreeSolvDataset,ESOLDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import *\n",
    "import torch\n",
    "from scipy.stats import pearsonr\n",
    "from tqdm import tqdm\n",
    "from model import Autoencoder # Simply importing the autoencoder model module from the model.py file\n",
    "from model import GNN3D,GNN3DFull\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem.Draw import MolsToGridImage\n",
    "\n",
    "import os\n",
    "datadir=\"../data/esol/\"\n",
    "modeldir=\"./models/esol_rmse_gnn3d/\"\n",
    "dataset_name=\"esol\"\n",
    "# Create datadir and modeldir folders if they don't exist\n",
    "if not os.path.exists(datadir):\n",
    "    os.makedirs(datadir)\n",
    "    \n",
    "if not os.path.exists(modeldir):\n",
    "    os.makedirs(modeldir)\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f15f0d0-0cb2-4642-84b0-5b63450abc49",
   "metadata": {},
   "source": [
    "## Split your dataset (SYD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc4c168-84d4-4b6b-9101-730733b54d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset from CSV\n",
    "dataset = pd.read_csv(datadir+dataset_name+\".csv\")\n",
    "\n",
    "# Split dataset into train and test\n",
    "train_dataset, test_dataset = split_dataset(dataset, 0.9)\n",
    "\n",
    "# Write train_dataset and test_dataset to CSV files\n",
    "train_dataset.to_csv(datadir+\"train.csv\", index=False)\n",
    "test_dataset.to_csv(datadir+\"test.csv\", index=False)\n",
    "\n",
    "print(\"Train and test datasets saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54da7a7-16b5-4c3d-9016-404ee9cc5d0d",
   "metadata": {},
   "source": [
    "## Process your data (PYD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a5b7a1-e495-4f9a-9afe-5f36a14e4ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = FreeSolvDataset(datadir+\"train\")\n",
    "print(train_samples)\n",
    "print(\"===================================\")\n",
    "test_samples = FreeSolvDataset(datadir+\"test\")\n",
    "print(test_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6992d9-9ff0-4e60-8c03-06e81c1265ac",
   "metadata": {},
   "source": [
    "## Know your featues (KYF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e120fd-0f78-40a9-b890-b237c8715434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing out the dimensions of all of these features with a description of what each feature is\n",
    "print(f\"Atomic Features: {(train_samples[0])[0].shape} - This represents the atomic features of the molecule\")\n",
    "print(f\"Bond Features: {(train_samples[0])[1].shape} - This represents the bond features of the molecule\")\n",
    "print(f\"Angle Features: {(train_samples[0])[2].shape} - This represents the angle features of the molecule\")\n",
    "print(f\"Dihedral Features: {(train_samples[0])[3].shape} - This represents the dihedral features of the molecule\")\n",
    "print(f\"Global Molecular Features: {(train_samples[0])[4].shape} - This represents the global molecular features of the molecule\")\n",
    "print(f\"Bond Indices: {(train_samples[0])[5].shape} - This represents the bond indices of the molecule\")\n",
    "print(f\"Angle Indices: {(train_samples[0])[6].shape} - This represents the angle indices of the molecule\")\n",
    "print(f\"Dihedral Indices: {(train_samples[0])[7].shape} - This represents the dihedral indices of the molecule\")\n",
    "print(f\"Target: {(train_samples[0])[8].shape} - This represents the target of the molecule\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b386540a-8acc-49bf-94b9-b8760824a501",
   "metadata": {},
   "source": [
    "## Know your modules (KYM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8573178-6a9e-4bcd-8fb6-168c142cf693",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gnn3d_vary_dataset_size(train_samples, min_samples=10, max_samples=45, divisions=3, n_epochs= 10, printstep=10, save_dir=\"./models/vary_train_size/\", dataset_name=\"logs\"):\n",
    "    \"\"\"Train GNN3D for varying training set size\"\"\"\n",
    "    # Create the directory if it does not exist\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "   \n",
    "    # Determine step size for each division\n",
    "    sample_step_size = int((max_samples - min_samples) / divisions) + 1\n",
    "\n",
    "    # Dictionary to store RMSE and MSE for each division\n",
    "    gnn_rmse_dict = {}\n",
    "\n",
    "    # Open a file to save the accumulated losses\n",
    "    losses_file = os.path.join(save_dir, f\"vary_size_gnn3d_losses_{dataset_name}.txt\")\n",
    "    with open(losses_file, 'w') as f:\n",
    "        f.write(f\"Training set size |\\tRMSE Loss |\\tMSE Loss\\n\")\n",
    "    \n",
    "        # Loop through divisions\n",
    "        for division_i in range(divisions + 1):\n",
    "            # Initialize training components for each division\n",
    "            # Aond and bond autoencoders' dimensions to be changed for a new dataset\n",
    "            atom_autoencoder = Autoencoder(154, 10).to(device)\n",
    "            bond_autoencoder = Autoencoder(10, 3).to(device)\n",
    "            mse_loss_fn = torch.nn.MSELoss()\n",
    "            gnn3d = GNN3D(atomic_vector_size=10, bond_vector_size=3, number_of_molecular_features=200, number_of_targets=1).to(device)\n",
    "            gnn_optimizer = torch.optim.Adam(gnn3d.parameters())\n",
    "\n",
    "            for epoch_i in range(n_epochs):\n",
    "                # Average losses initialization\n",
    "                avg_rmse = 0\n",
    "                avg_mse = 0\n",
    "\n",
    "                # Current size of the training set for this division\n",
    "                current_size = min_samples + sample_step_size * division_i\n",
    "\n",
    "                # Initialize dictionary entry for current division\n",
    "                gnn_rmse_dict[\"d\" + str(current_size)] = {\"avg_rmse\": [], \"avg_mse\": []}\n",
    "\n",
    "                # Training loop for current division\n",
    "                for sample_i in tqdm(range(len(train_samples)), desc=f\"Division {division_i + 1}/{divisions + 1}\"):\n",
    "                    if sample_i >= current_size:\n",
    "                        break\n",
    "\n",
    "                    molecule = train_samples[sample_i]\n",
    "                    target = molecule[8].to(device)\n",
    "\n",
    "                    input_representation = [\n",
    "                        atom_autoencoder.encode(molecule[0].to(device)),\n",
    "                        bond_autoencoder.encode(molecule[1].to(device)),\n",
    "                        molecule[2].to(device),\n",
    "                        molecule[3].to(device),\n",
    "                        molecule[4].to(device),\n",
    "                        molecule[5].to(device),\n",
    "                        molecule[6].to(device),\n",
    "                        molecule[7].to(device)\n",
    "                    ]\n",
    "\n",
    "                    # Forward pass\n",
    "                    prediction = gnn3d(input_representation)\n",
    "\n",
    "                    # Compute loss\n",
    "                    loss = mse_loss_fn(prediction, target)\n",
    "\n",
    "                    # Backward pass and optimization step\n",
    "                    gnn_optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    gnn_optimizer.step()\n",
    "\n",
    "                    # Update average RMSE and MSE\n",
    "                    avg_rmse = (avg_rmse * sample_i + torch.sqrt(loss).item()) / (sample_i + 1)\n",
    "                    avg_mse = (avg_mse * sample_i + loss.item()) / (sample_i + 1)\n",
    "                    gnn_rmse_dict[\"d\" + str(current_size)][\"avg_rmse\"].append(avg_rmse)\n",
    "                    gnn_rmse_dict[\"d\" + str(current_size)][\"avg_mse\"].append(avg_mse)\n",
    "\n",
    "                    if (sample_i % printstep == 0):\n",
    "                        print(f\"Epoch: {epoch_i:>3} | Samples: {sample_i:>6}/{current_size:>3} | RMSE Loss: {avg_rmse:.4f} | MSE Loss: {avg_mse:.4f} | target: {target.item():.4f} | pred: {prediction.item():.4f}\")\n",
    "    \n",
    "            # Save losses to a file\n",
    "            f.write(f\"{current_size}\\t{avg_rmse}\\t{avg_mse}\\n\")\n",
    "        \n",
    "        # Save model state after each division\n",
    "        torch.save(gnn3d.state_dict(), f\"{save_dir}gnn3d_{dataset_name}_div{current_size}.pth\")\n",
    "\n",
    "    return gnn_rmse_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4222d615-2453-4270-b041-13c7976ee160",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gnn_rmse_dict= train_gnn3d_vary_dataset_size(train_samples, min_samples=100, max_samples=500, divisions=5, n_epochs= 10, printstep=32, save_dir=modeldir, dataset_name=dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674cc302-9d0b-4f0d-8c9f-40bef3f94fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all divisions on the same plot\n",
    "plt.figure(figsize=(10, 6))  # Adjust figure size as needed\n",
    "\n",
    "for key in gnn_rmse_dict.keys():\n",
    "    plt.plot(gnn_rmse_dict[key][\"avg_rmse\"], label=f\"dataset size = {key[1:]}\")\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"GNN3D RMSE Loss for Different Dataset Sizes\")\n",
    "plt.xlabel(\"Training set size\")\n",
    "plt.ylabel(\"RMSE Loss\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(f\"{modeldir}gnn3d_{dataset_name}_all_divisions.svg\", format='svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ce2298-c8e1-439e-a0ef-fd5b727a0081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_autoencoder_model(samples, atom_autoencoder, bond_autoencoder, n_epochs=10, printstep=10, save_dir=\"./models/\", dataset_name=\"logs\"):\n",
    "    \"\"\"Train Autoencoder: Atom and bond\"\"\"\n",
    "    # Set the model in training mode\n",
    "    atom_autoencoder.train()\n",
    "    bond_autoencoder.train()\n",
    "\n",
    "    # Create the directory if it does not exist\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # Lists to store losses\n",
    "    avg_atom_rmse_losses = []\n",
    "    avg_bond_rmse_losses = []\n",
    "\n",
    "    for epoch_i in range(n_epochs):\n",
    "        avg_atom_rmse_loss = 0\n",
    "        avg_bond_rmse_loss = 0\n",
    "        total_samples = 0\n",
    "        \n",
    "        for i, molecule in enumerate(samples):\n",
    "            atom_features = molecule[0].to(device)\n",
    "            bond_features = molecule[1].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            atom_features_reconstructed = atom_autoencoder(atom_features)\n",
    "            bond_features_reconstructed = bond_autoencoder(bond_features)\n",
    "            \n",
    "            # Calculating loss\n",
    "            atom_loss = mse_loss_fn(atom_features_reconstructed, atom_features)\n",
    "            bond_loss = mse_loss_fn(bond_features_reconstructed, bond_features)\n",
    "            \n",
    "            # Backward pass and optimization step\n",
    "            atom_optimizer.zero_grad()\n",
    "            bond_optimizer.zero_grad()\n",
    "            atom_loss.backward()\n",
    "            bond_loss.backward()\n",
    "            atom_optimizer.step()\n",
    "            bond_optimizer.step()\n",
    "            \n",
    "            # Calculating average loss\n",
    "            avg_atom_rmse_loss = (avg_atom_rmse_loss * total_samples + torch.sqrt(atom_loss).item()) / (total_samples + 1)\n",
    "            avg_bond_rmse_loss = (avg_bond_rmse_loss * total_samples + torch.sqrt(bond_loss).item()) / (total_samples + 1)           \n",
    "            total_samples += 1\n",
    "\n",
    "            \n",
    "            if (i % printstep == 0):\n",
    "                print(f\"Epoch: {epoch_i:>3}/{n_epochs} | Samples: {i:>6}/{len(samples)} | Atom RMSE Loss: {avg_atom_rmse_loss:.4f} | Bond RMSE Loss: {avg_bond_rmse_loss:.4f}\")\n",
    "        \n",
    "        # Append average losses for the epoch to lists\n",
    "        avg_atom_rmse_losses.append(avg_atom_rmse_loss)\n",
    "        avg_bond_rmse_losses.append(avg_bond_rmse_loss)\n",
    "                \n",
    "    # Save the accumulated losses to a file\n",
    "    losses_file = os.path.join(save_dir, f\"autoencoder_losses_{dataset_name}.txt\")\n",
    "    with open(losses_file, 'w') as f:\n",
    "        f.write(f\"Epoch |\\tAtom RMSE Loss |\\tBond RMSE Loss\\n\")\n",
    "        for epoch_i in range(n_epochs):\n",
    "            f.write(f\"{epoch_i}\\t{avg_atom_rmse_losses[epoch_i]}\\t{avg_bond_rmse_losses[epoch_i]}\\n\")\n",
    "\n",
    "    # Save model state\n",
    "    torch.save(atom_autoencoder.state_dict(), f\"{save_dir}atom_autoencoder_{dataset_name}.pth\")\n",
    "    torch.save(bond_autoencoder.state_dict(), f\"{save_dir}bond_autoencoder_{dataset_name}.pth\")\n",
    "    \n",
    "    return avg_atom_rmse_losses, avg_bond_rmse_losses\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def process_molecule(molecule, atom_autoencoder, bond_autoencoder):\n",
    "    \"\"\"Separate input features and target\"\"\"\n",
    "    # Ensure molecule has at least 8 elements\n",
    "    if len(molecule) < 8:\n",
    "        return None, None\n",
    "    \n",
    "    target = molecule[8].to(device)  # Assuming target is the 9th element (index 8)\n",
    "    # Assuming first 8 elements are molecule graph input features:\n",
    "    # atomic_features, bond_features, angle_features, dihedral_features, \n",
    "    # global_molecular_features, bond_indices, angle_indices,  dihedral_indices    \n",
    "    molecule_data = [mol_elem.to(device) for mol_elem in molecule[:8]]\n",
    "    \n",
    "    # Putting latent atomic and bond features through encoders\n",
    "    molecule_data[0] = atom_autoencoder.encode(molecule_data[0])\n",
    "    molecule_data[1] = bond_autoencoder.encode(molecule_data[1])\n",
    "    \n",
    "    return molecule_data, target\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_gnn3d_model(gnn3d, samples, atom_autoencoder, bond_autoencoder, n_epochs=10, printstep=10, save_dir=\"./models/\", dataset_name=\"logs\"):\n",
    "    \"\"\"Train GNN3D\"\"\"\n",
    "    # Set the model in training mode\n",
    "    gnn3d.train()\n",
    "\n",
    "    # Create the directory if it does not exist\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "   \n",
    "    # Lists to store losses\n",
    "    avg_rmse_losses_train = []\n",
    "    avg_mse_losses_train = []\n",
    "    avg_rmse_losses_val = []\n",
    "    avg_mse_losses_val = []\n",
    "\n",
    "    # Start timing\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch_i in range(n_epochs):\n",
    "        # Training phase\n",
    "        avg_rmse_loss_train = 0\n",
    "        avg_mse_loss_train = 0\n",
    "        total_samples_train = 0\n",
    "    \n",
    "        for i in tqdm(range(len(train_part_samples)), desc='Training samples'):\n",
    "            molecule_data, target = process_molecule(train_part_samples[i], atom_autoencoder, bond_autoencoder)\n",
    "            if molecule_data is None:\n",
    "                continue\n",
    "        \n",
    "            prediction = gnn3d(molecule_data)\n",
    "            loss = mse_loss_fn(prediction, target)\n",
    "        \n",
    "            gnn_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            gnn_optimizer.step()\n",
    "        \n",
    "            avg_rmse_loss_train = (avg_rmse_loss_train * total_samples_train + torch.sqrt(loss).item()) / (total_samples_train + 1)\n",
    "            avg_mse_loss_train = (avg_mse_loss_train * total_samples_train + loss.item()) / (total_samples_train + 1)\n",
    "            total_samples_train += 1\n",
    "        \n",
    "            if (i % printstep == 0):\n",
    "                print(f\"Epoch: {epoch_i:>3} | Train Samples: {i:>6}/{len(train_part_samples)} | RMSE Loss: {avg_rmse_loss_train:.4f} | MSE Loss: {avg_mse_loss_train:.4f}\")\n",
    "    \n",
    "        # Validation phase\n",
    "        avg_rmse_loss_val = 0\n",
    "        avg_mse_loss_val = 0\n",
    "        total_samples_val = 0\n",
    "    \n",
    "        for i in tqdm(range(len(val_samples)), desc='Validation samples'):\n",
    "            molecule_data, target = process_molecule(val_samples[i], atom_autoencoder, bond_autoencoder)\n",
    "            if molecule_data is None:\n",
    "                continue\n",
    "        \n",
    "            prediction = gnn3d(molecule_data)\n",
    "            loss = mse_loss_fn(prediction, target)\n",
    "        \n",
    "            avg_rmse_loss_val = (avg_rmse_loss_val * total_samples_val + torch.sqrt(loss).item()) / (total_samples_val + 1)\n",
    "            avg_mse_loss_val = (avg_mse_loss_val * total_samples_val + loss.item()) / (total_samples_val + 1)\n",
    "            total_samples_val += 1\n",
    "        \n",
    "            if (i % printstep == 0):\n",
    "                print(f\"Epoch: {epoch_i:>3} | Val Samples: {i:>6}/{len(val_samples)} | RMSE Loss: {avg_rmse_loss_val:.4f} | MSE Loss: {avg_mse_loss_val:.4f}\")\n",
    "    \n",
    "        # Append average losses for the epoch to lists\n",
    "        avg_rmse_losses_train.append(avg_rmse_loss_train)\n",
    "        avg_mse_losses_train.append(avg_mse_loss_train)\n",
    "        avg_rmse_losses_val.append(avg_rmse_loss_val)\n",
    "        avg_mse_losses_val.append(avg_mse_loss_val)\n",
    "                \n",
    "    # Save the accumulated losses to a file\n",
    "    losses_file = os.path.join(save_dir, f\"gnn3d_losses_{dataset_name}.txt\")\n",
    "    with open(losses_file, 'w') as f:\n",
    "        f.write(f\"Epoch |\\tRMSE Train Loss |\\tMSE Train Loss |\\tRMSE Val Loss |\\tMSE Val Loss\\n\")\n",
    "        for epoch_i in range(n_epochs):\n",
    "            f.write(f\"{epoch_i}\\t{avg_rmse_losses_train[epoch_i]}\\t{avg_mse_losses_train[epoch_i]}\\t{avg_rmse_losses_val[epoch_i]}\\t{avg_mse_losses_val[epoch_i]}\\n\")\n",
    "\n",
    "    # Save model state\n",
    "    torch.save(gnn3d.state_dict(), f\"{save_dir}gnn3d_{dataset_name}.pth\")\n",
    "\n",
    "    # End timing\n",
    "    end_time = time.time()\n",
    "    \n",
    "    actual_time = end_time - start_time\n",
    "\n",
    "    actual_time_td = datetime.timedelta(seconds=actual_time)\n",
    "    hours = actual_time_td.seconds // 3600\n",
    "    minutes = (actual_time_td.seconds // 60) % 60\n",
    "    seconds = actual_time_td.seconds % 60\n",
    "    actual_time_str = f\"{hours} hours, {minutes} minutes, {seconds} seconds\"\n",
    "    \n",
    "    print(f\"Time taken for training: {actual_time_str}\")\n",
    "    \n",
    "    return avg_rmse_losses_train, avg_mse_losses_train, avg_rmse_losses_val, avg_mse_losses_val\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_gnn3d_model(gnn3d, samples, atom_autoencoder, bond_autoencoder):\n",
    "    \"\"\"Evaluate GNN3D\"\"\"\n",
    "    # Set the model in evaluation mode\n",
    "    gnn3d.eval()\n",
    "\n",
    "    # List to store predictions\n",
    "    predictions = []\n",
    "    targets = []\n",
    "    \n",
    "    avg_rmse_loss = 0\n",
    "    avg_mse_loss = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    # Start timing\n",
    "    start_time = time.time()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, molecule in enumerate(samples):\n",
    "            molecule_data, target = process_molecule(molecule, atom_autoencoder, bond_autoencoder)\n",
    "            if molecule_data is None:\n",
    "                continue\n",
    "            \n",
    "            # Forward pass\n",
    "            prediction = gnn3d(molecule_data)\n",
    "\n",
    "            # Extract target, prediction\n",
    "            target_value = target.item()\n",
    "            prediction_value = prediction.item()\n",
    "\n",
    "            # For every test samples\n",
    "            #print(f\"Target: {target.item():.4f} | Prediction: {prediction.item():.4f}\")\n",
    "    \n",
    "            # Store prediction\n",
    "            predictions.append(prediction_value)\n",
    "            targets.append(target_value)\n",
    "                        \n",
    "            # Calculating loss\n",
    "            loss = mse_loss_fn(prediction, target)\n",
    "                     \n",
    "            # Accumulate losses\n",
    "            avg_rmse_loss += (torch.sqrt(loss).item())\n",
    "            avg_mse_loss += loss.item()\n",
    "            total_samples += 1\n",
    "    \n",
    "    # Calculate average losses\n",
    "    avg_rmse_loss /= total_samples\n",
    "    avg_mse_loss /= total_samples\n",
    "\n",
    "    # End timing\n",
    "    end_time = time.time()\n",
    "\n",
    "    actual_time = end_time - start_time\n",
    "\n",
    "    actual_time_td = datetime.timedelta(seconds=actual_time)\n",
    "    hours = actual_time_td.seconds // 3600\n",
    "    minutes = (actual_time_td.seconds // 60) % 60\n",
    "    seconds = actual_time_td.seconds % 60\n",
    "    actual_time_str = f\"{hours} hours, {minutes} minutes, {seconds} seconds\"    \n",
    "    \n",
    "    print(f\"Evaluation Results:\")\n",
    "    print(f\"RMSE Loss: {avg_rmse_loss:.4f}\")\n",
    "    print(f\"MSE Loss: {avg_mse_loss:.4f}\")\n",
    "    print(f\"Time taken for evaluation: {actual_time_str}\")\n",
    "    \n",
    "    return predictions, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb3a1fa-cb1b-4397-a444-62b2126099e3",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4253885-98e8-48fb-8847-ba893b9c9b05",
   "metadata": {},
   "source": [
    "### Autoencoder training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b723752e-b5db-4c9f-8c77-e26dde760638",
   "metadata": {},
   "outputs": [],
   "source": [
    "atom_autoencoder = Autoencoder(154, 10).to(device)\n",
    "bond_autoencoder = Autoencoder(10, 3).to(device)\n",
    "mse_loss_fn = torch.nn.MSELoss()\n",
    "atom_optimizer = torch.optim.Adam(atom_autoencoder.parameters())\n",
    "bond_optimizer = torch.optim.Adam(bond_autoencoder.parameters())\n",
    "\n",
    "atom_losses, bond_losses = train_autoencoder_model(train_samples, atom_autoencoder, bond_autoencoder, n_epochs=20, printstep=32, save_dir=modeldir, dataset_name=dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792de4f6-df8a-4abf-ae05-f3909fb1fa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the losses (optional)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(atom_losses)+1), atom_losses, marker='o', linestyle='-', color='b', label='Atom RMSE Loss')\n",
    "#plt.plot(range(1, len(bond_losses)+1), bond_losses, marker='o', linestyle='-', color='r', label='Avg. Bond RMSE Loss')\n",
    "plt.title(f\"Atom Autoencoder Training Losses for {dataset_name}\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"RMSE Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(f\"{modeldir}atom_autoencoder_losses_{dataset_name}.png\")\n",
    "plt.show()\n",
    "\n",
    "# Plotting the losses (optional)\n",
    "plt.figure(figsize=(10, 6))\n",
    "#plt.plot(range(1, len(atom_losses)+1), atom_losses, marker='o', linestyle='-', color='b', label='Avg. Atom RMSE Loss')\n",
    "plt.plot(range(1, len(bond_losses)+1), bond_losses, marker='o', linestyle='-', color='r', label='Bond RMSE Loss')\n",
    "plt.title(f\"Bond Autoencoder Training Losses for {dataset_name}\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"RMSE Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(f\"{modeldir}bond_autoencoder_losses_{dataset_name}.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b95275-4edb-43d6-8227-a6130b511e11",
   "metadata": {},
   "source": [
    "### GNN3D training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172ce254-abbb-4219-8a31-c73f7d07f046",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_part_samples, val_samples = train_test_split(train_samples, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d98798d-a139-4616-bcb4-3608a98a934d",
   "metadata": {},
   "outputs": [],
   "source": [
    "atom_autoencoder = Autoencoder(154, 10).to(device)\n",
    "bond_autoencoder = Autoencoder(10, 3).to(device)\n",
    "mse_loss_fn = torch.nn.MSELoss()\n",
    "gnn3d = GNN3D(atomic_vector_size=10, bond_vector_size=3, number_of_molecular_features=200, number_of_targets=1).to(device)\n",
    "gnn_optimizer = torch.optim.Adam(gnn3d.parameters())\n",
    "rmse_losses_train, mse_losses_train, rmse_losses_val, mse_losses_val = train_gnn3d_model(gnn3d, train_samples, atom_autoencoder, bond_autoencoder, n_epochs=25, printstep=32, save_dir=modeldir, dataset_name=dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f592be3f-b874-404b-8670-b6906befd044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming rmse_losses is the list of RMSE losses obtained from training\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(rmse_losses_train)+1), rmse_losses_train, marker='o', linestyle='-', color='b', label='Train RMSE Loss')\n",
    "plt.plot(range(1, len(rmse_losses_val)+1), rmse_losses_val, marker='x', linestyle='-', color='r', label='Validation RMSE Loss')\n",
    "plt.title(f\"GNN3D Training Losses for {dataset_name}\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"RMSE Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(f\"{modeldir}gnn3d_rmse_losses_{dataset_name}.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa98e0ed-50d8-4e68-afcf-7815cbcb79d5",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a26bc02-bb5c-4769-a820-fad17f0e09a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, targets = evaluate_gnn3d_model(gnn3d, test_samples, atom_autoencoder, bond_autoencoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d98a0d-b64b-4269-a10a-a171cc096398",
   "metadata": {},
   "source": [
    "## Know your correlations (KYC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadc1bf-0623-4fa4-933e-d0685a905298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate R^2\n",
    "def calculate_r_squared(predictions, targets):\n",
    "    ss_tot = np.sum((targets - np.mean(targets))**2)\n",
    "    ss_res = np.sum((targets - predictions)**2)\n",
    "    r_squared = 1 - (ss_res / ss_tot)\n",
    "    return r_squared\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "predictions = np.array(predictions)\n",
    "targets = np.array(targets)\n",
    "\n",
    "# Calculate Pearson correlation coefficient\n",
    "corr, _ = pearsonr(predictions, targets)\n",
    "\n",
    "print(f\"Pearson Correlation Coefficient: {corr:.4f}\")\n",
    "\n",
    "r_squared = calculate_r_squared(predictions, targets)\n",
    "print(f\"Coefficient of Determination R^2: {r_squared:.4f}\")\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(targets, predictions, color='blue', alpha=0.5)\n",
    "plt.plot(targets, targets, color='red', linestyle='-', linewidth=2)  # Plot y=x line\n",
    "plt.text(np.min(targets), np.max(predictions), f\"Pearson Correlation: {corr:.4f}\", fontsize=12, verticalalignment='top')\n",
    "plt.title('Scatter Plot of Predictions vs Targets')\n",
    "plt.xlabel('Targets')\n",
    "plt.ylabel('Predictions')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5364b2e7-e72a-47c5-8f71-6d33975d7bb9",
   "metadata": {},
   "source": [
    "## Know your molecules and true/prediction (Be warned if there is skipped molecule from test_samples! No skip -> correct structure!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f5d46f-d71f-4cd3-ad15-a29624a91746",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Loaded train samples: {len(train_samples)}\")\n",
    "print(f\"Loaded test samples: {len(test_samples)}\")\n",
    "print(f\"Total (train+test): {len(train_samples) + len(test_samples)}\" )\n",
    "print(f\"Total from dataset: {len(dataset)}\")\n",
    "print(f\"80% of dataset: {int(0.8*len(dataset))}\")\n",
    "print(f\"20% of dataset: {int(0.2*len(dataset))}\")\n",
    "print(f\"NOT Skipped molecule, therefore following output of next cell is correct!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802587be-8f1a-40d7-9159-89752437e927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test_samples from CSV\n",
    "test_dataset = pd.read_csv(datadir+\"test.csv\")\n",
    "molecules = test_dataset['smiles'].apply(lambda x: Chem.MolFromSmiles(x)) \n",
    "\n",
    "y_true = [targets[i] for i in range(len(test_samples))]\n",
    "y_pred = [predictions[i] for i in range(len(test_samples))]\n",
    "\n",
    "legends = [f\"y_true/y_pred = {y_true[i]:.2f}/{y_pred[i]:.2f}\" for i in range(len(test_samples))]\n",
    "MolsToGridImage(molecules, molsPerRow=5, maxMols=100,legends=legends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2d2fdd-5c41-46e1-8acb-b0c68c514a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(datadir+\"test.csv\")      #Reading logS: y_true dataframe\n",
    "df['preds'] = predictions\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555f0723-eef6-483b-893a-3d04581b6aa7",
   "metadata": {},
   "source": [
    "## Future task: What is so unique about dihedral angles?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c64eed-5662-468d-b76e-94ff50eebc6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
